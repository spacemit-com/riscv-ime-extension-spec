[[example]]
== Example of convolution compute

Using dot-product matrix multiply-accumulate instructions and sliding-window dot-product matrix multiply-accumulate instructions, we can accelerate the computation of 2D convolution. Given an input feature map size of 1x3x8x8(NHWC), kernel size of 3x3, with stride = 1, padding = 0, and an output channel number O_c is  4, the size of the output feature map will be 1x4x6x6(HWC).

Using the following three instructions, achieve the effects shown in Figures 9, 10, and 11. Each time, the value stored in the current VD vector register will be accumulated with the value obtained from this matrix multiplication.

....
vmadot     vd, vs1, vs2
vmadot1    vd, vs1, vs2'
vmadot2    vd, vs1, vs2''
....

This implementation accomplishes the calculation of the first row within the receptive field of the feature map and the first row of the convolution. The calculations for the second and third rows are carried out in the same accumulative manner as described above, as shown in Figures 12 and 13, respectively.

To slide the input feature map, padding with zeros is performed due to the row direction being less than 8. At this point, the values in the VS1 register only need to be transferred from the previous round's VS1+1 register, and the values in the VS1+1 register can be set to zero. By following the representation method shown in Figure 15, the output feature map can be computed, thus completing the 2D convolution operation.
